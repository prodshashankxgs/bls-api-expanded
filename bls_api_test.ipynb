{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Import libraries\nfrom load_data_enhanced import load_data\nfrom bls_package import get_available_categories\nimport pandas as pd\n\n# Get all available tickers from Excel file\ntickers = get_available_categories(200)  # Fetch up to 200 categories\nprint(f\"Found {len(tickers)} tickers\")\n\n# Load data for all tickers\ndata = load_data(tickers, \"2025-06\")\n\n# Create DataFrame\ndf = pd.DataFrame(data)\n\n# Print DataFrame\nprint(df)"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T18:14:27.590288Z",
     "start_time": "2025-07-24T18:14:27.558280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Using the BLS Client Module (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to BLS API at http://localhost:8000\n",
      "   Data available: True\n"
     ]
    }
   ],
   "source": [
    "# Create BLS API client\n",
    "client = BLSClient(API_URL)\n",
    "\n",
    "# The client will automatically test the connection when created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get ALL available categories from the API\ntry:\n    all_categories = client.get_categories(200)  # Get up to 200 categories\n    print(f\"\\nFound {len(all_categories)} total categories:\")\n    print(\"First 20 categories:\")\n    for i, cat in enumerate(all_categories[:20], 1):\n        print(f\"   {i:2d}. {cat}\")\n    \n    if len(all_categories) > 20:\n        print(f\"\\n... and {len(all_categories) - 20} more categories\")\n        \n    # Store all categories for testing\n    test_categories = all_categories\nexcept Exception as e:\n    print(f\"Could not retrieve all categories: {e}\")\n    # Fallback to subset if API fails\n    test_categories = [\n        \"All items\",\n        \"Food\", \n        \"Energy\",\n        \"Shelter\",\n        \"Transportation\",\n        \"Medical care\"\n    ]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Basic Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Use all available categories for comprehensive testing\ntarget_date = \"2025-06\"\n\nprint(f\"Loading data for ALL {len(test_categories)} categories from Excel file\")\nprint(f\"Target Date: {target_date}\")\nprint(f\"\\nSample categories to be tested:\")\nfor i, cat in enumerate(test_categories[:10], 1):\n    print(f\"   {i}. {cat}\")\nif len(test_categories) > 10:\n    print(f\"   ... and {len(test_categories) - 10} more\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# use load_data function to print the dataframe\nclient.load_data(test_categories, target_date)"
  },
  {
   "cell_type": "code",
   "source": "# Create separate NSA and SA columns and show actual index values\nif df is not None:\n    print(\"creating separate nsa/sa columns with actual index values:\")\n    print(\"=\" * 60)\n    \n    # Create a clean dataframe with separate NSA/SA columns\n    result_df = df[['category']].copy()\n    \n    # Add NSA columns\n    nsa_cols = [col for col in df.columns if col.startswith('nsa_')]\n    for nsa_col in nsa_cols:\n        # Extract date from column name and create cleaner column name\n        date_part = nsa_col.replace('nsa_', '')\n        result_df[f'nsa_{date_part}'] = df[nsa_col]\n    \n    # Add SA columns  \n    sa_cols = [col for col in df.columns if col.startswith('sa_')]\n    for sa_col in sa_cols:\n        # Extract date from column name and create cleaner column name\n        date_part = sa_col.replace('sa_', '')\n        result_df[f'sa_{date_part}'] = df[sa_col]\n    \n    print(f\"processed {len(result_df)} categories\")\n    print(f\"columns: {list(result_df.columns)}\")\n    \n    # Display first 15 rows showing actual index values\n    print(f\"\\nactual index values (first 15 categories):\")\n    display(result_df.head(15))\n    \n    # Show summary statistics for the actual index values\n    numeric_cols = [col for col in result_df.columns if col != 'category']\n    if numeric_cols:\n        print(f\"\\nsummary statistics for actual index values:\")\n        print(\"=\" * 50)\n        for col in numeric_cols[:4]:  # Show first 4 numeric columns\n            values = result_df[col].dropna()\n            if len(values) > 0:\n                print(f\"{col}:\")\n                print(f\"   mean: {values.mean():.3f}\")\n                print(f\"   min:  {values.min():.3f}\")\n                print(f\"   max:  {values.max():.3f}\")\n                print(f\"   range: {values.max() - values.min():.3f}\")\n                print()\n    \n    # Save the complete dataset\n    print(f\"total categories processed: {len(result_df)}\")\n    print(f\"data includes all categories from excel file\")\nelse:\n    print(\"no data available to process\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}